---
layout: post
permalink: /01ead88355127f33e70117da2578556e80ac1dbc/:categories/:year/:month/:day/:title:output_ext
title:  "Mitigating Data Drift through Early Detection"
description: "Exploring binary classification to detect data drift"
type: card-dated
image: http://placehold.it/750X300?text=Header+Image # for local images, place in /assets/img/posts/
caption: 
categories: post
tags: 
  - Data Drift
author: Jose
card: card-1
---


# Introduction

`Data drift` poses a major challenge in machine learning, where the distribution of data changes over time. This can degrade model performance when applied to new, unseen data. This report provides an experimental study of data drift detection.

# Theory

The hypothesis is that a binary classification model trained to detect differences between training and production data can indicate data drift. This is because such a model would learn underlying patterns to distinguish between the datasets, signaling distribution changes.

To quantify data drift, Matthew's correlation coefficient (MCC) will be used. MCC measures binary classification quality, accounting for true positives, true negatives, false positives and false negatives. It ranges from -1 to 1, where 1 is a perfect model, and 0 indicates random guessing. A high MCC implies significant data drift.

# Implementation

The implementation entailed:

1. Collecting original training and new production data
2. Merging and labeling data (0 for original, 1 for new)
3. Randomly splitting into train/eval sets
4. Training a binary classification model on the train set
5. Evaluating on the eval set
6. Calculating the MCC
7. Inferring data drift if MCC > 0.2

The model used was a binary image classifier based on MobileNet-v2 architecture, well-suited for this task.
An alternative approach in this scenario could have been to use a dimensionality reductiontechnique, such as PCA or t-SNE, in combination with k-nearest neighbors (KNN)classification. This approach would have involved reducing the dimensionality of the data to alower number of features and then training a KNN classifier to distinguish between the twodatasets based on the reduced features.

# Experiments

Experiment 1 tested for data drift within the same project dataset. Two shuffled groups of 400 images were created from the training set, labeled as original and new data. The model achieved an MCC of 0.083, indicating no detectable difference between the groups, as expected.

Experiment 2 tested for drift between our project's training data and new data collected in July 2022. Following the same methodology with 400 images per set, the model achieved an MCC of 0.863. This high score indicates significant drift between the datasets.

Experiments 3 and 4 applied the same approach to another project's data, yielding similar results.

# Conclusion

The experiments demonstrate using a MobileNet-v2 based binary classifier to effectively detect data drift when present. This method can be applied to production data from different periods or customers. Detecting drift early allows mitigation to maintain model accuracy over time.

# Links

[Detecting Data Drift with Machine Learning](https://medium.com/bigdatarepublic/detecting-data-drift-with-machine-learning-adb177544312)
