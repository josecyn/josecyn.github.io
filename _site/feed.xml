<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="http://localhost:4000//feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000//" rel="alternate" type="text/html" /><updated>2021-06-15T16:38:34+09:00</updated><id>http://localhost:4000//feed.xml</id><title type="html">Home</title><author><name>Jose Carlos Yanez</name></author><entry><title type="html">Steel Beam counting</title><link href="http://localhost:4000//post/2021/06/15/Beam-Counting.html" rel="alternate" type="text/html" title="Steel Beam counting" /><published>2021-06-15T07:17:00+09:00</published><updated>2021-06-15T07:17:00+09:00</updated><id>http://localhost:4000//post/2021/06/15/Beam-Counting</id><content type="html" xml:base="http://localhost:4000//post/2021/06/15/Beam-Counting.html">&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;The task in this project was to count the number of beams in the image.&lt;/p&gt;

&lt;p&gt;At the beginning of the project, I was aked to do segmentation and then count the pieces based on the 
shapes segmented.&lt;/p&gt;

&lt;p&gt;After that, I proposed to do object detection as I thought it could lead to higher accuracy.&lt;/p&gt;

&lt;p&gt;In order to perform object detection I chose 2 different architectures: CenterNet and YOLOv3.&lt;/p&gt;

&lt;p&gt;Let’s go through each step of the project.&lt;/p&gt;

&lt;h3 id=&quot;segmentation&quot;&gt;Segmentation&lt;/h3&gt;

&lt;p&gt;I used the famous &lt;a href=&quot;https://github.com/matterport/Mask_RCNN&quot;&gt;Mask RCNN&lt;/a&gt; repository. At this point, the 
dataset was even less than 1000 pictures. For&lt;/p&gt;</content><author><name>Jose</name></author><category term="post" /><category term="Pytorch" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://placehold.it/750X300?text=Header+Image" /><media:content medium="image" url="http://placehold.it/750X300?text=Header+Image" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Pytorch Quantization Of YOLOv3 Family</title><link href="http://localhost:4000//post/2021/06/14/Quantization.html" rel="alternate" type="text/html" title="Pytorch Quantization Of YOLOv3 Family" /><published>2021-06-14T20:19:00+09:00</published><updated>2021-06-14T20:19:00+09:00</updated><id>http://localhost:4000//post/2021/06/14/Quantization</id><content type="html" xml:base="http://localhost:4000//post/2021/06/14/Quantization.html">&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;In this document I will go through the process of quantize an existing YOLOv3 model using Pytorch.
Please note that nowadays, May 2021, Pytorch does not support quantization using GPU!&lt;/p&gt;

&lt;p&gt;Quantization refers to convert input, weights and biases to floating point 16 or integer 8 bits.
Operations in floating point 32 bits have additional precision that isn’t needed for the model to have a high accuracy.
Because of that, the use of smaller precision increases execution speed while keeping a good accuracy.&lt;/p&gt;

&lt;p&gt;However, when converting to integer 8, the impact is obviously bigger and some steps have to be taken in order to preserve the model’s accuracy.&lt;/p&gt;

&lt;p&gt;In this guide we will take a look at those steps. We will focus on int8 because that is
where you can decrease the execution time the most.&lt;/p&gt;

&lt;h2 id=&quot;first-steps&quot;&gt;First Steps&lt;/h2&gt;

&lt;p&gt;The idea of quantization is to convert the input of the model to int8, execute the forward pass
and convert the result back to floating point.
This approach is fine, but sometimes the model may contain operations that do not support int8 input.&lt;/p&gt;

&lt;p&gt;Check the following link to have a look at the &lt;a href=&quot;https://pytorch.org/docs/stable/quantization-support.html&quot;&gt;supported operators&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you use a simple model such as MobileNet or even ResNet, all operators are supported and you don’t have to change the code that much.&lt;/p&gt;

&lt;p&gt;As stated in the introduction, nowadays, Pytorch only support quantization using CPU. Because of that, you have to
load or move the model to the GPU.&lt;/p&gt;

&lt;p&gt;In the case of YOLOv3 and YOLOv3-tiny I found that I was using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leakyRELU&lt;/code&gt; which is not supported.
So I replaced the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leakyRELU&lt;/code&gt; by plain &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RELU&lt;/code&gt;.
After this replacement, I retrained the model for a few epochs just to adapt to the new component.
This is an important step! Afterwards, check the model’s accuracy, it should not have changed that much.&lt;/p&gt;

&lt;p&gt;Of course, there may be other operators that are not supported and can’t be changed so easily.
In the case of YOLOv3 you can see that the YOLO layer is, of course, not supported.
Moreover, in the case of the YOLOv3-tiny version I used, the operation &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ZeroPad&lt;/code&gt;, which is not supported.&lt;/p&gt;

&lt;p&gt;Let’s see in the next chapter how can we deal with such cases.&lt;/p&gt;

&lt;h2 id=&quot;unsupported-operations-what-to-do&quot;&gt;Unsupported operations, what to do&lt;/h2&gt;

&lt;p&gt;Other than replacing the operator with a similar one like we did with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;leakyRELU&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RELU&lt;/code&gt;,
there is another possibility, but first we need to know how quantization internally works.&lt;/p&gt;

&lt;p&gt;When we quantize weights, biases and operators, we switch from fp32 data to int8 data.
When executing the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;forward&lt;/code&gt; pass, if one operator expects fp32 data and receives int8 data, it will fail and vice versa will also fail.
That’s why Pytorch offers the possibility to convert data from/to int8 and fp32.
The name of functions for that purpose are: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DeQuantStub&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;QuantStub&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;So, if we have an unsupported operator, the only thing you need to do is convert its input data from int8 to fp32.
Of course, this conversion takes time and memory so, in terms of performance, the least changes the better.&lt;/p&gt;

&lt;p&gt;To have a clear view, it would be something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/quantization/dequantstub_quantstub.png&quot; alt=&quot;Iterative forward&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Note that between supported operations you don’t need to change the data type.&lt;/p&gt;

&lt;p&gt;Let’s see an example of how to control this flow programmatically.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;QuantStub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dequant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DeQuantStub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# create model
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;yolo_outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;noquant_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_noquant_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# get no quant operations index
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_isquant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# quant control
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noquant_layers&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_isquant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dequant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_isquant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noquant_layers&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_isquant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_isquant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In this example, I get the “no quant layers” at the beginning calling the method &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.get_noquant_layers()&lt;/code&gt;.
It returns a list with the unsupported layers index.
Those layers need fp32 input, so if the data is in int8 format, we need to convert it.
That’s why I added a “quant control” block.
The quant control block checks whether the module that’s about to be executed needs fp32 or not.
In case the module needs fp32 input, and the input is int8 type, we convert it.
In case the module needs int8 and the data is of type fp32, we also convert it back to int8.&lt;/p&gt;

&lt;p&gt;For those conversions, You have to create 2 properties in the model constructor &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__init__(self)&lt;/code&gt;.
Note the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.quant()&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.dequant()&lt;/code&gt; methods.&lt;/p&gt;

&lt;h2 id=&quot;fusing-operations&quot;&gt;Fusing Operations&lt;/h2&gt;

&lt;p&gt;Now, that the forward flow is correct, let’s take a step further.
Pytorch has a few already optimized operators that include multiple operations inside just one operation.
For example &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ConvReLU2d&lt;/code&gt; includes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;convolution + relu&lt;/code&gt; operations.
You can find these operations in this &lt;a href=&quot;https://pytorch.org/docs/stable/quantization-support.html#torch-nn-intrinsic&quot;&gt;list&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, using these combined operations we can extract a little bit more of performance.
Pytorch provides a function for that task that is called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torch.quantization.fuse_modules()&lt;/code&gt;.
This is an example on how to use it:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fuse_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fuse_modules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'conv'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'batch_norm'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the code above, we go through all the sequential modules checking whether the first element is a convolution layer.
If that is the case, we call the Pytorch method with the keys we use in our model &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;['conv', 'batch_norm', 'relu']&lt;/code&gt;.
Pytorch will take those operations and merge them in a single one such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ConvReLU2d&lt;/code&gt; (Conv2d + ReLU).&lt;/p&gt;

&lt;p&gt;Example before fusing:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(0): Sequential(
      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (batch_norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After fusing:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(0): Sequential(
      (conv): ConvReLU2d(
        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
      )
      (batch_norm): Identity()
      (relu): Identity()
    )
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note the use of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Identity()&lt;/code&gt; operation in the replaced operators &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_norm&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;relu&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;After fusing those operators, execute a validation on the model to check that the accuracy didn’t decrease.
The model accuracy should be the same.&lt;/p&gt;

&lt;h2 id=&quot;what-to-do-with-skip-connections&quot;&gt;What To Do With Skip Connections&lt;/h2&gt;

&lt;p&gt;In &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResNet&lt;/code&gt; networks and many other architectures, we may use skip connections. In YOLOv3 architecture we do, and it needs to be handled.
If you just concatenate 2 tensors using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torch.cat()&lt;/code&gt; and both tensors have the same datatype (int8 or fp32) it should be fine.
However, when skipping connections the addition &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+&lt;/code&gt; operator is often used.
In that case, we need to update this operator to work with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int8&lt;/code&gt; input.&lt;/p&gt;

&lt;p&gt;To achieve that, you have to declare a new property in your class like this:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.f_add = nn.quantized.FloatFunctional()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It has to be at class level because this operation will be calibrated so it has to save statistics. It can’t be created ‘on the fly’.&lt;/p&gt;

&lt;p&gt;When executing the addition operation, you can use it like this:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x = self.f_add.add(x, previous_x)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Of course you have to pay attention that the datatypes of the tensors &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;previous_x&lt;/code&gt; match!&lt;/p&gt;

&lt;p&gt;This is how it looks when the model structure is printed:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(17): Connect(
  (f_add): FloatFunctional(
    (activation_post_process): Identity()
  )
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;different-quantization-methods&quot;&gt;Different Quantization Methods&lt;/h2&gt;

&lt;p&gt;Once the model is ready, we can start the process of post-training quantization.&lt;/p&gt;

&lt;p&gt;Let’s see 2 options:&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;post-training static quantization&lt;/strong&gt; method, involves not just converting the weights from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;float&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int&lt;/code&gt;, as in dynamic quantization,
but also performing the additional step of first feeding batches of data through the network and
computing the resulting distributions of the different activations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Post-training quantization-aware training (QAT)&lt;/strong&gt; is the quantization method that typically results in the &lt;strong&gt;highest accuracy&lt;/strong&gt;.
With QAT, all weights and activations are “fake quantized” during both the forward and backward passes of training:
that is, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;float&lt;/code&gt; values are rounded to mimic &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;int8&lt;/code&gt; values, but all computations are still done with floating point numbers.
Thus, all the weight adjustments during training are made while “aware” of the fact that the model will ultimately be quantized;
after quantizing, therefore, this method will usually yield higher accuracy than either dynamic quantization or post-training static quantization.&lt;/p&gt;

&lt;h2 id=&quot;how-to-set-the-quantization-configuration&quot;&gt;How To Set The Quantization Configuration&lt;/h2&gt;

&lt;p&gt;There are currently 2 different configurations for the quantization process:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fbgemm&lt;/code&gt; (for use on x86, https://github.com/pytorch/FBGEMM) and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qnnpack&lt;/code&gt; (for use on the ARM QNNPACK library https://github.com/pytorch/QNNPACK).&lt;/p&gt;

&lt;p&gt;In this case, I am targeting ARM processors, so the best configuration to choose should be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qnnpack&lt;/code&gt;.
However, I would recommend you to try both methods.&lt;/p&gt;

&lt;p&gt;The code to set the configuration and prepare the model couldn’t be easier, but it depends on the quantization method:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;qconfig = torch.quantization.get_default_qconfig('qnnpack')
torch.quantization.prepare(model, inplace=True)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, if you are using &lt;strong&gt;quantization aware training&lt;/strong&gt; method, you have to call this function:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qconfig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_default_qat_qconfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'qnnpack'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prepare_qat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;When printing the configuration, the output looks like this (QAT training):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;QConfig(activation=functools.partial(&amp;lt;class 'torch.quantization.fake_quantize.FakeQuantize'&amp;gt;, observer=&amp;lt;class 'torch.quantization.observer.MovingAverageMinMaxObserver'&amp;gt;, quant_min=0, quant_max=255, reduce_range=False), weight=functools.partial(&amp;lt;class 'torch.quantization.fake_quantize.FakeQuantize'&amp;gt;, observer=&amp;lt;class 'torch.quantization.observer.MovingAverageMinMaxObserver'&amp;gt;, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, reduce_range=False))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you want to check manually if the observers were correctly placed, you can just print the module like this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It prints the information of the first element in the first layer (static quantization).&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ConvReLU2d(
 (0): Conv2d(
   3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
   (activation_post_process): HistogramObserver()
 )
 (1): ReLU(
   (activation_post_process): HistogramObserver()
 )
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;HistogramObserver()&lt;/code&gt; functions.&lt;/p&gt;

&lt;p&gt;And this is how it looks for QAT:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; ConvReLU2d(
  3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
  (activation_post_process): FakeQuantize(
    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), scale=tensor([1.]), zero_point=tensor([0])
    (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([]), max_val=tensor([]))
  )
  (weight_fake_quant): FakeQuantize(
    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), scale=tensor([1.]), zero_point=tensor([0])
    (activation_post_process): MovingAverageMinMaxObserver(min_val=tensor([]), max_val=tensor([]))
  )
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FakeQuantize()&lt;/code&gt; functions.&lt;/p&gt;

&lt;h2 id=&quot;post-training-quantization-general-steps&quot;&gt;Post-training Quantization General Steps&lt;/h2&gt;

&lt;p&gt;basic steps to perform post-training static quantization:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Load model&lt;/li&gt;
  &lt;li&gt;Evaluate the model to get the baseline accuracy&lt;/li&gt;
  &lt;li&gt;Fuse possible operations (for example: conv, bn and relu)&lt;/li&gt;
  &lt;li&gt;[Optional] check the baseline accuracy again (should be the same as in step 2)&lt;/li&gt;
  &lt;li&gt;Set quantization configuration&lt;/li&gt;
  &lt;li&gt;Calibrate / QAT train&lt;/li&gt;
  &lt;li&gt;Convert the model to quantized model&lt;/li&gt;
  &lt;li&gt;Evaluate the model to check accuracy regarding baseline&lt;/li&gt;
  &lt;li&gt;Save the quantized model&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the step 6, depending on your quantization method, you will calibrate or do QAT training.
Read the following sections to understand the difference between them.&lt;/p&gt;

&lt;h3 id=&quot;post-training-static-quantization-calibration&quot;&gt;Post-Training Static Quantization Calibration&lt;/h3&gt;

&lt;p&gt;In the process of calibration, we set the model in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eval()&lt;/code&gt; mode and execute inference using training data.
Pytorch captures the distributions of the activations automatically.&lt;/p&gt;

&lt;p&gt;In the calibration process you can use a subset or the whole training set. And you can even do multiple epochs.
I would test different options and compare the results.&lt;/p&gt;

&lt;p&gt;So, there’s nothing else to add about the calibration step, you just have to do inference. Just keep in
mind to use a representative set of data of the distribution of your dataset.&lt;/p&gt;

&lt;p&gt;Let’s see how the quantization-aware-training differs from calibration in the next section.&lt;/p&gt;

&lt;h3 id=&quot;post-training-quantization-aware-training&quot;&gt;Post-training Quantization Aware Training&lt;/h3&gt;

&lt;p&gt;In static quantization we did a calibration step where we executed inference.
In QAT training, you just have to train the model as you would normally for a few epochs.
During forward and backward Pytorch will collect statistics that will use later during quantization.
Additionally, you can also do some tricks to try to increase accuracy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Switch batch norm to use running mean and variance towards the end of training to better match inference numerics.&lt;/li&gt;
  &lt;li&gt;We also freeze the quantizer parameters (scale and zero-point) and fine tune the weights.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example of training loop:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cal_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'QAT Training process epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cal_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_loaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'train'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# training epoch
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Freeze quantizer parameters
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disable_observer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Freeze batch norm mean and variance estimates
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;intrinsic&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;freeze_bn_stats&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Check the accuracy after each epoch
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;quantized_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inplace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantized_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'test'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;## QAT Model Evaluation Results Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;##&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pprint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pprint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metrics&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'QAT Training done'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Again, I encourage you to test different parameters.
Please note that this process can be veeeeery slow for big datasets or many epochs.&lt;/p&gt;

&lt;h2 id=&quot;save-model&quot;&gt;Save model&lt;/h2&gt;

&lt;p&gt;When saving for using in a mobile device, for example, you have to do it in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jit&lt;/code&gt; format.
For example:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_traced_module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_random_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# get_random_input just uses torch.randn
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;save&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_traced_module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;quantized_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;imsize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;export_file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;summary-whole-process-step-by-step&quot;&gt;Summary Whole Process Step-by-Step&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Train a floating point model or load a pre-trained floating point model.&lt;/li&gt;
  &lt;li&gt;Move the model to CPU and switch model to evaluation mode.&lt;/li&gt;
  &lt;li&gt;Apply layer fusion and check if the layer fusion results in correct model.&lt;/li&gt;
  &lt;li&gt;Apply torch.quantization.QuantStub() and torch.quantization.QuantStub() to the inputs and outputs, respectively.&lt;/li&gt;
  &lt;li&gt;Specify quantization configurations, such as symmetric quantization or asymmetric quantization, etc.&lt;/li&gt;
  &lt;li&gt;Prepare quantization model for post-training calibration.&lt;/li&gt;
  &lt;li&gt;Run post-training calibration.&lt;/li&gt;
  &lt;li&gt;Convert the calibrated floating point model to quantized integer model.&lt;/li&gt;
  &lt;li&gt;[Optional] Verify accuracies and inference performance gain.&lt;/li&gt;
  &lt;li&gt;Save the quantized integer model.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;mobile-optimization&quot;&gt;Mobile Optimization&lt;/h2&gt;

&lt;p&gt;Apart from using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;qnnpack&lt;/code&gt; configuration, you can also take a few measures.
I particularly like this link: https://pytorch.org/tutorials/recipes/mobile_perf.html&lt;/p&gt;

&lt;p&gt;Check it out!&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Using quantization techniques you can reduce the model’s execution time while
having a close accuracy to the baseline. Execution speed can be 2x-4x faster (depending on
multiple factors) and the model size will be reduced too, because the weights are stored directly in int8
taking less space in your memory.&lt;/p&gt;

&lt;h2 id=&quot;links&quot;&gt;Links&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;https://pytorch.org/tutorials/recipes/mobile_perf.html&lt;/li&gt;
  &lt;li&gt;https://pytorch.org/tutorials/advanced/static_quantization_tutorial.html&lt;/li&gt;
  &lt;li&gt;https://pytorch.org/docs/stable/quantization.html&lt;/li&gt;
  &lt;li&gt;https://leimao.github.io/blog/PyTorch-Static-Quantization/&lt;/li&gt;
  &lt;li&gt;https://pytorch.org/docs/stable/quantization-support.html&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jose</name></author><category term="post" /><category term="Pytorch" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://placehold.it/750X300?text=Header+Image" /><media:content medium="image" url="http://placehold.it/750X300?text=Header+Image" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Handwritten character recognition</title><link href="http://localhost:4000//post/2021/06/13/Belt-conveyor.html" rel="alternate" type="text/html" title="Handwritten character recognition" /><published>2021-06-13T15:49:00+09:00</published><updated>2021-06-13T15:49:00+09:00</updated><id>http://localhost:4000//post/2021/06/13/Belt-conveyor</id><content type="html" xml:base="http://localhost:4000//post/2021/06/13/Belt-conveyor.html">&lt;h3 id=&quot;introduction&quot;&gt;Introduction&lt;/h3&gt;

&lt;p&gt;In this project I created a demo of handwritten character recognition.&lt;/p&gt;

&lt;p&gt;In the team we had a previous experience working on a problem like this, and I decided to showcase
that solution.&lt;/p&gt;

&lt;p&gt;The idea of this demo is to use a robot arm and a belt conveyor to simulate a industrial environment where 
this technology could be used. The robot arm picks up a box with handwritten characters and places it on the belt conveyor.
A camera located next to the belt, is recording video all the time. Using deep learning models the text on the side
of the boxes is detected, recognized and the result is added to the list on the right.&lt;/p&gt;

&lt;p&gt;Handwritten character recognition is not a complex problem, so I decided to make it more
difficult including that the text can be in any direction and that it must run at a decent speed on a 
NVIDIA Jetson.&lt;/p&gt;

&lt;p&gt;This is the result:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/belt.gif&quot; alt=&quot;Conveyor belt&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It runs at real time 30fps and when it detects a pice of text it runs at 7fps. Still smooth enough.&lt;/p&gt;

&lt;p&gt;The data has been manually collected and labeled. 
There were few examples, so this also adds up in the global difficulty of the project.&lt;/p&gt;

&lt;h3 id=&quot;methodology&quot;&gt;Methodology&lt;/h3&gt;

&lt;p&gt;This is a 2-step process:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Detect text in the image, crop and rotate&lt;/li&gt;
  &lt;li&gt;Apply character recognition to the result of the first step&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;motivation&quot;&gt;Motivation&lt;/h3&gt;

&lt;p&gt;In this demo I wanted to support any alphanumeric character (plus hyphen) in any direction (up, right, down and left).
At first I wanted to solve this problem with a single model, but soon I realised that it is too complex.&lt;/p&gt;

&lt;p&gt;If you have one class for each character in any direction you end up with many classes, around 150.&lt;/p&gt;

&lt;p&gt;So I decided to split the detection of the text and the character in two different models.
The first one will carry text detection. When it detects some text in the image, it will crop around it 
and it will rotate to the up position.&lt;/p&gt;

&lt;p&gt;Once the text has been cropped and rotated, the second model will carry over and perform character recognition.&lt;/p&gt;

&lt;h3 id=&quot;first-model-text-detection&quot;&gt;First Model: Text Detection&lt;/h3&gt;

&lt;p&gt;The first task is to detect text. This is a classic object detection problem with 4 classes: up, right, down and left.&lt;/p&gt;

&lt;p&gt;At first it seemed quite easy, so I decided to apply one of the fastest architectures in terms of inference time: &lt;strong&gt;YOLOv3 tiny&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;I have a lot of experience with YOLOv3 tiny and the results were very good from the very beginning. 
I tried to keep the resolution as low as possible and endeup with a input image size of 288x160 pixels.&lt;/p&gt;

&lt;p&gt;A couple of examples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/belt_conveyor/belt_text1.png&quot; alt=&quot;Conveyor belt text detection ex1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/belt_conveyor/belt_text2.png&quot; alt=&quot;Conveyor belt text detection ex2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It is a very fast model, it runs at 30fps on this hardware 
so I was happy with the result and moved to the next subproblem; &lt;strong&gt;character recognition&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;second-model-character-recognition&quot;&gt;Second Model: Character Recognition&lt;/h3&gt;

&lt;p&gt;This is a much harder problem. 
I tried to apply the same architecture as in the previous step, but it didn’t work so well.&lt;/p&gt;

&lt;p&gt;So I decided to apply a bigger network: &lt;strong&gt;YOLOv3&lt;/strong&gt;. As it is a bigger network, it can understand more variations of 
the characters so it can generalize much better.&lt;/p&gt;

&lt;p&gt;After working on the parameter tunning, I got a very good model.&lt;/p&gt;

&lt;p&gt;One of the key parameters was the input &lt;strong&gt;image size&lt;/strong&gt;. Inference time is very important in this project because we have 
very limited resources. We had 16:9 images, so it was key not to add padding to the images 
(this could increase inference time by 30%). It was also very important to keep a low resolution. 
I got a working model with high accuracy and then iterated until I reached a good accuracy at the smallest resolution.
In that case the final input image size was 384x192 pixels.&lt;/p&gt;

&lt;p&gt;A couple of examples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/belt_conveyor/belt_char1.png&quot; alt=&quot;Conveyor belt character recognition ex1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/posts/belt_conveyor/belt_char2.png&quot; alt=&quot;Conveyor belt character recognition ex2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As expected, this model is slower than the text detection one.
In order to improve inference time, I skip some frames, I don’t perform character 
recognition of every frame detected. This could have been achieved increasing the batch size with similar results.&lt;/p&gt;

&lt;h3 id=&quot;additional-information&quot;&gt;Additional Information&lt;/h3&gt;

&lt;p&gt;Additionally to the deep learning models I also developed the desktop application.
The application was made in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Python&lt;/code&gt; using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tkinter&lt;/code&gt; library.&lt;/p&gt;

&lt;p&gt;The Robot arm is a &lt;a href=&quot;https://www.dobot.cc/dobot-magician/product-overview.html&quot;&gt;Magician Dobot&lt;/a&gt; and it is controlled using the Python API provided by the vendor.&lt;/p&gt;

&lt;p&gt;The camera is a simple logitech webcam.&lt;/p&gt;

&lt;p&gt;Everything runs on a NVIDIA Jetson TX2.&lt;/p&gt;

&lt;p&gt;The models were trained using &lt;a href=&quot;https://github.com/AlexeyAB/darknet&quot;&gt;AlexeyAB’s darknet repository&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I also tried to run those models on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TensorRT&lt;/code&gt; and I succeded. But because of time constraints I decided to 
implement the whole program in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Python&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If you have questions regarding this project, don’t hesitate to contact me!&lt;/p&gt;</content><author><name>Jose</name></author><category term="post" /><category term="computer vision" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://placehold.it/750X300?text=Header+Image" /><media:content medium="image" url="http://placehold.it/750X300?text=Header+Image" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000//post/2020/10/30/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2020-10-30T09:01:21+09:00</published><updated>2020-10-30T09:01:21+09:00</updated><id>http://localhost:4000//post/2020/10/30/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000//post/2020/10/30/welcome-to-jekyll.html">&lt;p&gt;You’ll find this post in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;Jekyll requires blog post files to be named according to the following format:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR-MONTH-DAY-title.MARKUP&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;YEAR&lt;/code&gt; is a four-digit number, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MONTH&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DAY&lt;/code&gt; are both two-digit numbers, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;MARKUP&lt;/code&gt; is the file extension representing the format used in the file. After that, include the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name>Tyler Butler</name></author><category term="post" /><category term="jekyll" /><summary type="html">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://placehold.it/750X300?text=Header+Image" /><media:content medium="image" url="http://placehold.it/750X300?text=Header+Image" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Dumbarton Style Guide</title><link href="http://localhost:4000//post/2020/10/29/Dumbarton-Style-Guide.html" rel="alternate" type="text/html" title="Dumbarton Style Guide" /><published>2020-10-29T09:01:21+09:00</published><updated>2020-10-29T09:01:21+09:00</updated><id>http://localhost:4000//post/2020/10/29/Dumbarton-Style-Guide</id><content type="html" xml:base="http://localhost:4000//post/2020/10/29/Dumbarton-Style-Guide.html">&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#markdown&quot;&gt;Markdown&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#bootstrap&quot;&gt;Bootstrap&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;[Custom CSS]&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;markdown&quot;&gt;Markdown&lt;/h1&gt;

&lt;h1 id=&quot;heading-&quot;&gt;Heading &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#&lt;/code&gt;&lt;/h1&gt;
&lt;h2 id=&quot;heading--1&quot;&gt;Heading &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;##&lt;/code&gt;&lt;/h2&gt;
&lt;h3 id=&quot;heading&quot;&gt;Heading&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;###&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;heading--2&quot;&gt;Heading &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;####&lt;/code&gt;&lt;/h4&gt;
&lt;h5 id=&quot;heading-1&quot;&gt;Heading&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#####&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;&lt;em&gt;italics&lt;/em&gt;  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*italics*&lt;/code&gt;&lt;br /&gt;
&lt;strong&gt;Bold&lt;/strong&gt;   &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;**Bold**&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Code Highlighting&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;my_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Hello from a function&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;my_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;Block Quote&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Tables&lt;/p&gt;

&lt;table class=&quot;mbtablestyle&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Syntax&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Description&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Test Text&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Header&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Title&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;Here’s this&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Paragraph&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Text&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;And more&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here’s a simple footnote,&lt;sup id=&quot;fnref:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and here’s a longer one.&lt;sup id=&quot;fnref:bignote&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:bignote&quot; class=&quot;footnote&quot; rel=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h1 id=&quot;bootstrap&quot;&gt;Bootstrap&lt;/h1&gt;
&lt;p&gt;This theme uses Bootstrap 4 CDN. In addition to markdown, you can use raw bootstrap HTML to format posts and pages. For a full list of options, check out the &lt;a href=&quot;https://getbootstrap.com/docs/4.5/getting-started/introduction/&quot;&gt;Documentation&lt;/a&gt; page.&lt;/p&gt;

&lt;div class=&quot;alert alert-primary&quot; role=&quot;alert&quot;&gt;
  A simple primary alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-secondary&quot; role=&quot;alert&quot;&gt;
  A simple secondary alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-success&quot; role=&quot;alert&quot;&gt;
  A simple success alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-danger&quot; role=&quot;alert&quot;&gt;
  A simple danger alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-warning&quot; role=&quot;alert&quot;&gt;
  A simple warning alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-info&quot; role=&quot;alert&quot;&gt;
  A simple info alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-light&quot; role=&quot;alert&quot;&gt;
  A simple light alert—check it out!
&lt;/div&gt;
&lt;div class=&quot;alert alert-dark&quot; role=&quot;alert&quot;&gt;
  A simple dark alert—check it out!
&lt;/div&gt;

&lt;h1&gt;Example heading &lt;span class=&quot;badge badge-secondary&quot;&gt;New&lt;/span&gt;&lt;/h1&gt;
&lt;h2&gt;Example heading &lt;span class=&quot;badge badge-secondary&quot;&gt;New&lt;/span&gt;&lt;/h2&gt;
&lt;h3&gt;Example heading &lt;span class=&quot;badge badge-secondary&quot;&gt;New&lt;/span&gt;&lt;/h3&gt;
&lt;h4&gt;Example heading &lt;span class=&quot;badge badge-secondary&quot;&gt;New&lt;/span&gt;&lt;/h4&gt;
&lt;h5&gt;Example heading &lt;span class=&quot;badge badge-secondary&quot;&gt;New&lt;/span&gt;&lt;/h5&gt;
&lt;h6&gt;Example heading &lt;span class=&quot;badge badge-secondary&quot;&gt;New&lt;/span&gt;&lt;/h6&gt;

&lt;nav aria-label=&quot;breadcrumb&quot;&gt;
  &lt;ol class=&quot;breadcrumb&quot;&gt;
    &lt;li class=&quot;breadcrumb-item active&quot; aria-current=&quot;page&quot;&gt;Home&lt;/li&gt;
  &lt;/ol&gt;
&lt;/nav&gt;

&lt;nav aria-label=&quot;breadcrumb&quot;&gt;
  &lt;ol class=&quot;breadcrumb&quot;&gt;
    &lt;li class=&quot;breadcrumb-item&quot;&gt;&lt;a href=&quot;#&quot;&gt;Home&lt;/a&gt;&lt;/li&gt;
    &lt;li class=&quot;breadcrumb-item active&quot; aria-current=&quot;page&quot;&gt;Library&lt;/li&gt;
  &lt;/ol&gt;
&lt;/nav&gt;

&lt;nav aria-label=&quot;breadcrumb&quot;&gt;
  &lt;ol class=&quot;breadcrumb&quot;&gt;
    &lt;li class=&quot;breadcrumb-item&quot;&gt;&lt;a href=&quot;#&quot;&gt;Home&lt;/a&gt;&lt;/li&gt;
    &lt;li class=&quot;breadcrumb-item&quot;&gt;&lt;a href=&quot;#&quot;&gt;Library&lt;/a&gt;&lt;/li&gt;
    &lt;li class=&quot;breadcrumb-item active&quot; aria-current=&quot;page&quot;&gt;Data&lt;/li&gt;
  &lt;/ol&gt;
&lt;/nav&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-primary&quot;&gt;Primary&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot;&gt;Secondary&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-success&quot;&gt;Success&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-danger&quot;&gt;Danger&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-warning&quot;&gt;Warning&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-info&quot;&gt;Info&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-light&quot;&gt;Light&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-dark&quot;&gt;Dark&lt;/button&gt;&lt;/p&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-link&quot;&gt;Link&lt;/button&gt;&lt;/p&gt;

&lt;div class=&quot;btn-group&quot; role=&quot;group&quot; aria-label=&quot;Button group with nested dropdown&quot;&gt;
  &lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot;&gt;1&lt;/button&gt;
  &lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot;&gt;2&lt;/button&gt;

  &lt;div class=&quot;btn-group&quot; role=&quot;group&quot;&gt;
    &lt;button id=&quot;btnGroupDrop1&quot; type=&quot;button&quot; class=&quot;btn btn-secondary dropdown-toggle&quot; data-toggle=&quot;dropdown&quot; aria-haspopup=&quot;true&quot; aria-expanded=&quot;false&quot;&gt;
      Dropdown
    &lt;/button&gt;
    &lt;div class=&quot;dropdown-menu&quot; aria-labelledby=&quot;btnGroupDrop1&quot;&gt;
      &lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot;&gt;Dropdown link&lt;/a&gt;
      &lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot;&gt;Dropdown link&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;card&quot; style=&quot;width: 18rem;&quot;&gt;
  &lt;img src=&quot;http://placehold.it/150x150&quot; class=&quot;card-img-top&quot; alt=&quot;...&quot; /&gt;
  &lt;div class=&quot;card-body&quot;&gt;
    &lt;h5 class=&quot;card-title&quot;&gt;Card title&lt;/h5&gt;
    &lt;p class=&quot;card-text&quot;&gt;Some quick example text to build on the card title and make up the bulk of the card's content.&lt;/p&gt;
  &lt;/div&gt;
  &lt;ul class=&quot;list-group list-group-flush&quot;&gt;
    &lt;li class=&quot;list-group-item&quot;&gt;Cras justo odio&lt;/li&gt;
    &lt;li class=&quot;list-group-item&quot;&gt;Dapibus ac facilisis in&lt;/li&gt;
    &lt;li class=&quot;list-group-item&quot;&gt;Vestibulum at eros&lt;/li&gt;
  &lt;/ul&gt;
  &lt;div class=&quot;card-body&quot;&gt;
    &lt;a href=&quot;#&quot; class=&quot;card-link&quot;&gt;Card link&lt;/a&gt;
    &lt;a href=&quot;#&quot; class=&quot;card-link&quot;&gt;Another link&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;!-- Example split danger button --&gt;
&lt;div class=&quot;btn-group&quot;&gt;
  &lt;button type=&quot;button&quot; class=&quot;btn btn-danger&quot;&gt;Action&lt;/button&gt;
  &lt;button type=&quot;button&quot; class=&quot;btn btn-danger dropdown-toggle dropdown-toggle-split&quot; data-toggle=&quot;dropdown&quot; aria-haspopup=&quot;true&quot; aria-expanded=&quot;false&quot;&gt;
    &lt;span class=&quot;sr-only&quot;&gt;Toggle Dropdown&lt;/span&gt;
  &lt;/button&gt;
  &lt;div class=&quot;dropdown-menu&quot;&gt;
    &lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot;&gt;Action&lt;/a&gt;
    &lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot;&gt;Another action&lt;/a&gt;
    &lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot;&gt;Something else here&lt;/a&gt;
    &lt;div class=&quot;dropdown-divider&quot;&gt;&lt;/div&gt;
    &lt;a class=&quot;dropdown-item&quot; href=&quot;#&quot;&gt;Separated link&lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;form&gt;
  &lt;div class=&quot;form-group row&quot;&gt;
    &lt;label for=&quot;inputEmail3&quot; class=&quot;col-sm-2 col-form-label&quot;&gt;Email&lt;/label&gt;
    &lt;div class=&quot;col-sm-10&quot;&gt;
      &lt;input type=&quot;email&quot; class=&quot;form-control&quot; id=&quot;inputEmail3&quot; /&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;form-group row&quot;&gt;
    &lt;label for=&quot;inputPassword3&quot; class=&quot;col-sm-2 col-form-label&quot;&gt;Password&lt;/label&gt;
    &lt;div class=&quot;col-sm-10&quot;&gt;
      &lt;input type=&quot;password&quot; class=&quot;form-control&quot; id=&quot;inputPassword3&quot; /&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;fieldset class=&quot;form-group&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
      &lt;legend class=&quot;col-form-label col-sm-2 pt-0&quot;&gt;Radios&lt;/legend&gt;
      &lt;div class=&quot;col-sm-10&quot;&gt;
        &lt;div class=&quot;form-check&quot;&gt;
          &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gridRadios&quot; id=&quot;gridRadios1&quot; value=&quot;option1&quot; checked=&quot;&quot; /&gt;
          &lt;label class=&quot;form-check-label&quot; for=&quot;gridRadios1&quot;&gt;
            First radio
          &lt;/label&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-check&quot;&gt;
          &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gridRadios&quot; id=&quot;gridRadios2&quot; value=&quot;option2&quot; /&gt;
          &lt;label class=&quot;form-check-label&quot; for=&quot;gridRadios2&quot;&gt;
            Second radio
          &lt;/label&gt;
        &lt;/div&gt;
        &lt;div class=&quot;form-check disabled&quot;&gt;
          &lt;input class=&quot;form-check-input&quot; type=&quot;radio&quot; name=&quot;gridRadios&quot; id=&quot;gridRadios3&quot; value=&quot;option3&quot; disabled=&quot;&quot; /&gt;
          &lt;label class=&quot;form-check-label&quot; for=&quot;gridRadios3&quot;&gt;
            Third disabled radio
          &lt;/label&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/fieldset&gt;
  &lt;div class=&quot;form-group row&quot;&gt;
    &lt;div class=&quot;col-sm-2&quot;&gt;Checkbox&lt;/div&gt;
    &lt;div class=&quot;col-sm-10&quot;&gt;
      &lt;div class=&quot;form-check&quot;&gt;
        &lt;input class=&quot;form-check-input&quot; type=&quot;checkbox&quot; id=&quot;gridCheck1&quot; /&gt;
        &lt;label class=&quot;form-check-label&quot; for=&quot;gridCheck1&quot;&gt;
          Example checkbox
        &lt;/label&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;form-group row&quot;&gt;
    &lt;div class=&quot;col-sm-10&quot;&gt;
      &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Sign in&lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/form&gt;

&lt;div class=&quot;input-group mb-3&quot;&gt;
  &lt;div class=&quot;input-group-prepend&quot;&gt;
    &lt;span class=&quot;input-group-text&quot; id=&quot;basic-addon1&quot;&gt;@&lt;/span&gt;
  &lt;/div&gt;
  &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Username&quot; aria-label=&quot;Username&quot; aria-describedby=&quot;basic-addon1&quot; /&gt;
&lt;/div&gt;

&lt;div class=&quot;input-group mb-3&quot;&gt;
  &lt;input type=&quot;text&quot; class=&quot;form-control&quot; placeholder=&quot;Recipient's username&quot; aria-label=&quot;Recipient's username&quot; aria-describedby=&quot;basic-addon2&quot; /&gt;
  &lt;div class=&quot;input-group-append&quot;&gt;
    &lt;span class=&quot;input-group-text&quot; id=&quot;basic-addon2&quot;&gt;@example.com&lt;/span&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;label for=&quot;basic-url&quot;&gt;Your vanity URL&lt;/label&gt;&lt;/p&gt;
&lt;div class=&quot;input-group mb-3&quot;&gt;
  &lt;div class=&quot;input-group-prepend&quot;&gt;
    &lt;span class=&quot;input-group-text&quot; id=&quot;basic-addon3&quot;&gt;https://example.com/users/&lt;/span&gt;
  &lt;/div&gt;
  &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;basic-url&quot; aria-describedby=&quot;basic-addon3&quot; /&gt;
&lt;/div&gt;

&lt;div class=&quot;input-group mb-3&quot;&gt;
  &lt;div class=&quot;input-group-prepend&quot;&gt;
    &lt;span class=&quot;input-group-text&quot;&gt;$&lt;/span&gt;
  &lt;/div&gt;
  &lt;input type=&quot;text&quot; class=&quot;form-control&quot; aria-label=&quot;Amount (to the nearest dollar)&quot; /&gt;
  &lt;div class=&quot;input-group-append&quot;&gt;
    &lt;span class=&quot;input-group-text&quot;&gt;.00&lt;/span&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;input-group&quot;&gt;
  &lt;div class=&quot;input-group-prepend&quot;&gt;
    &lt;span class=&quot;input-group-text&quot;&gt;With textarea&lt;/span&gt;
  &lt;/div&gt;
  &lt;textarea class=&quot;form-control&quot; aria-label=&quot;With textarea&quot;&gt;&lt;/textarea&gt;
&lt;/div&gt;

&lt;div class=&quot;jumbotron&quot;&gt;
  &lt;h1 class=&quot;display-4&quot;&gt;Hello, world!&lt;/h1&gt;
  &lt;p class=&quot;lead&quot;&gt;This is a simple hero unit, a simple jumbotron-style component for calling extra attention to featured content or information.&lt;/p&gt;
  &lt;hr class=&quot;my-4&quot; /&gt;
  &lt;p&gt;It uses utility classes for typography and spacing to space content out within the larger container.&lt;/p&gt;
  &lt;a class=&quot;btn btn-primary btn-lg&quot; href=&quot;#&quot; role=&quot;button&quot;&gt;Learn more&lt;/a&gt;
&lt;/div&gt;

&lt;ul class=&quot;list-group&quot;&gt;
  &lt;li class=&quot;list-group-item d-flex justify-content-between align-items-center&quot;&gt;
    Cras justo odio
    &lt;span class=&quot;badge badge-primary badge-pill&quot;&gt;14&lt;/span&gt;
  &lt;/li&gt;
  &lt;li class=&quot;list-group-item d-flex justify-content-between align-items-center&quot;&gt;
    Dapibus ac facilisis in
    &lt;span class=&quot;badge badge-primary badge-pill&quot;&gt;2&lt;/span&gt;
  &lt;/li&gt;
  &lt;li class=&quot;list-group-item d-flex justify-content-between align-items-center&quot;&gt;
    Morbi leo risus
    &lt;span class=&quot;badge badge-primary badge-pill&quot;&gt;1&lt;/span&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;list-group&quot;&gt;
  &lt;button type=&quot;button&quot; class=&quot;list-group-item list-group-item-action active&quot;&gt;
    Cras justo odio
  &lt;/button&gt;
  &lt;button type=&quot;button&quot; class=&quot;list-group-item list-group-item-action&quot;&gt;Dapibus ac facilisis in&lt;/button&gt;
  &lt;button type=&quot;button&quot; class=&quot;list-group-item list-group-item-action&quot;&gt;Morbi leo risus&lt;/button&gt;
  &lt;button type=&quot;button&quot; class=&quot;list-group-item list-group-item-action&quot;&gt;Porta ac consectetur ac&lt;/button&gt;
  &lt;button type=&quot;button&quot; class=&quot;list-group-item list-group-item-action&quot; disabled=&quot;&quot;&gt;Vestibulum at eros&lt;/button&gt;
&lt;/div&gt;

&lt;ul class=&quot;list-unstyled&quot;&gt;
  &lt;li class=&quot;media&quot;&gt;
    &lt;img src=&quot;http://placehold.it/150x150&quot; class=&quot;mr-3&quot; alt=&quot;...&quot; /&gt;
    &lt;div class=&quot;media-body&quot;&gt;
      &lt;h5 class=&quot;mt-0 mb-1&quot;&gt;List-based media object&lt;/h5&gt;
      Cras sit amet nibh libero, in gravida nulla. Nulla vel metus scelerisque ante sollicitudin. Cras purus odio, vestibulum in vulputate at, tempus viverra turpis. Fusce condimentum nunc ac nisi vulputate fringilla. Donec lacinia congue felis in faucibus.
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li class=&quot;media my-4&quot;&gt;
    &lt;img src=&quot;http://placehold.it/150x150&quot; class=&quot;mr-3&quot; alt=&quot;...&quot; /&gt;
    &lt;div class=&quot;media-body&quot;&gt;
      &lt;h5 class=&quot;mt-0 mb-1&quot;&gt;List-based media object&lt;/h5&gt;
      Cras sit amet nibh libero, in gravida nulla. Nulla vel metus scelerisque ante sollicitudin. Cras purus odio, vestibulum in vulputate at, tempus viverra turpis. Fusce condimentum nunc ac nisi vulputate fringilla. Donec lacinia congue felis in faucibus.
    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li class=&quot;media&quot;&gt;
    &lt;img src=&quot;http://placehold.it/150x150&quot; class=&quot;mr-3&quot; alt=&quot;...&quot; /&gt;
    &lt;div class=&quot;media-body&quot;&gt;
      &lt;h5 class=&quot;mt-0 mb-1&quot;&gt;List-based media object&lt;/h5&gt;
      Cras sit amet nibh libero, in gravida nulla. Nulla vel metus scelerisque ante sollicitudin. Cras purus odio, vestibulum in vulputate at, tempus viverra turpis. Fusce condimentum nunc ac nisi vulputate fringilla. Donec lacinia congue felis in faucibus.
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;modal&quot; tabindex=&quot;-1&quot;&gt;
  &lt;div class=&quot;modal-dialog&quot;&gt;
    &lt;div class=&quot;modal-content&quot;&gt;
      &lt;div class=&quot;modal-header&quot;&gt;
        &lt;h5 class=&quot;modal-title&quot;&gt;Modal title&lt;/h5&gt;
        &lt;button type=&quot;button&quot; class=&quot;close&quot; data-dismiss=&quot;modal&quot; aria-label=&quot;Close&quot;&gt;
          &lt;span aria-hidden=&quot;true&quot;&gt;&amp;times;&lt;/span&gt;
        &lt;/button&gt;
      &lt;/div&gt;
      &lt;div class=&quot;modal-body&quot;&gt;
        &lt;p&gt;Modal body text goes here.&lt;/p&gt;
      &lt;/div&gt;
      &lt;div class=&quot;modal-footer&quot;&gt;
        &lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-dismiss=&quot;modal&quot;&gt;Close&lt;/button&gt;
        &lt;button type=&quot;button&quot; class=&quot;btn btn-primary&quot;&gt;Save changes&lt;/button&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;div class=&quot;row&quot;&gt;
  &lt;div class=&quot;col-3&quot;&gt;
    &lt;div class=&quot;nav flex-column nav-pills&quot; id=&quot;v-pills-tab&quot; role=&quot;tablist&quot; aria-orientation=&quot;vertical&quot;&gt;
      &lt;a class=&quot;nav-link active&quot; id=&quot;v-pills-home-tab&quot; data-toggle=&quot;pill&quot; href=&quot;#v-pills-home&quot; role=&quot;tab&quot; aria-controls=&quot;v-pills-home&quot; aria-selected=&quot;true&quot;&gt;Home&lt;/a&gt;
      &lt;a class=&quot;nav-link&quot; id=&quot;v-pills-profile-tab&quot; data-toggle=&quot;pill&quot; href=&quot;#v-pills-profile&quot; role=&quot;tab&quot; aria-controls=&quot;v-pills-profile&quot; aria-selected=&quot;false&quot;&gt;Profile&lt;/a&gt;
      &lt;a class=&quot;nav-link&quot; id=&quot;v-pills-messages-tab&quot; data-toggle=&quot;pill&quot; href=&quot;#v-pills-messages&quot; role=&quot;tab&quot; aria-controls=&quot;v-pills-messages&quot; aria-selected=&quot;false&quot;&gt;Messages&lt;/a&gt;
      &lt;a class=&quot;nav-link&quot; id=&quot;v-pills-settings-tab&quot; data-toggle=&quot;pill&quot; href=&quot;#v-pills-settings&quot; role=&quot;tab&quot; aria-controls=&quot;v-pills-settings&quot; aria-selected=&quot;false&quot;&gt;Settings&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class=&quot;col-9&quot;&gt;
    &lt;div class=&quot;tab-content&quot; id=&quot;v-pills-tabContent&quot;&gt;
      &lt;div class=&quot;tab-pane fade show active&quot; id=&quot;v-pills-home&quot; role=&quot;tabpanel&quot; aria-labelledby=&quot;v-pills-home-tab&quot;&gt;...&lt;/div&gt;
      &lt;div class=&quot;tab-pane fade&quot; id=&quot;v-pills-profile&quot; role=&quot;tabpanel&quot; aria-labelledby=&quot;v-pills-profile-tab&quot;&gt;...&lt;/div&gt;
      &lt;div class=&quot;tab-pane fade&quot; id=&quot;v-pills-messages&quot; role=&quot;tabpanel&quot; aria-labelledby=&quot;v-pills-messages-tab&quot;&gt;...&lt;/div&gt;
      &lt;div class=&quot;tab-pane fade&quot; id=&quot;v-pills-settings&quot; role=&quot;tabpanel&quot; aria-labelledby=&quot;v-pills-settings-tab&quot;&gt;...&lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
$('#myTab a').on('click', function (e) {
  e.preventDefault()
  $(this).tab('show')
})
&lt;/script&gt;

&lt;!-- Image and text --&gt;
&lt;nav class=&quot;navbar navbar-light bg-light&quot;&gt;
  &lt;a class=&quot;navbar-brand&quot; href=&quot;#&quot;&gt;
    &lt;img src=&quot;/docs/4.5/assets/brand/bootstrap-solid.svg&quot; width=&quot;30&quot; height=&quot;30&quot; class=&quot;d-inline-block align-top&quot; alt=&quot;&quot; loading=&quot;lazy&quot; /&gt;
    Bootstrap
  &lt;/a&gt;
&lt;/nav&gt;

&lt;nav class=&quot;navbar navbar-dark bg-dark&quot;&gt;
  &lt;!-- Navbar content --&gt;
&lt;/nav&gt;

&lt;nav class=&quot;navbar navbar-dark bg-primary&quot;&gt;
  &lt;!-- Navbar content --&gt;
&lt;/nav&gt;

&lt;nav class=&quot;navbar navbar-light&quot; style=&quot;background-color: #e3f2fd;&quot;&gt;
  &lt;!-- Navbar content --&gt;
&lt;/nav&gt;

&lt;nav aria-label=&quot;Page navigation example&quot;&gt;
  &lt;ul class=&quot;pagination justify-content-center&quot;&gt;
    &lt;li class=&quot;page-item disabled&quot;&gt;
      &lt;a class=&quot;page-link&quot; href=&quot;#&quot; tabindex=&quot;-1&quot; aria-disabled=&quot;true&quot;&gt;Previous&lt;/a&gt;
    &lt;/li&gt;
    &lt;li class=&quot;page-item&quot;&gt;&lt;a class=&quot;page-link&quot; href=&quot;#&quot;&gt;1&lt;/a&gt;&lt;/li&gt;
    &lt;li class=&quot;page-item&quot;&gt;&lt;a class=&quot;page-link&quot; href=&quot;#&quot;&gt;2&lt;/a&gt;&lt;/li&gt;
    &lt;li class=&quot;page-item&quot;&gt;&lt;a class=&quot;page-link&quot; href=&quot;#&quot;&gt;3&lt;/a&gt;&lt;/li&gt;
    &lt;li class=&quot;page-item&quot;&gt;
      &lt;a class=&quot;page-link&quot; href=&quot;#&quot;&gt;Next&lt;/a&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-container=&quot;body&quot; data-toggle=&quot;popover&quot; data-placement=&quot;top&quot; data-content=&quot;Vivamus sagittis lacus vel augue laoreet rutrum faucibus.&quot;&gt;
  Popover on top
&lt;/button&gt;&lt;/p&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-container=&quot;body&quot; data-toggle=&quot;popover&quot; data-placement=&quot;right&quot; data-content=&quot;Vivamus sagittis lacus vel augue laoreet rutrum faucibus.&quot;&gt;
  Popover on right
&lt;/button&gt;&lt;/p&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-container=&quot;body&quot; data-toggle=&quot;popover&quot; data-placement=&quot;bottom&quot; data-content=&quot;Vivamus sagittis lacus vel augue laoreet rutrum faucibus.&quot;&gt;
  Popover on bottom
&lt;/button&gt;&lt;/p&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-container=&quot;body&quot; data-toggle=&quot;popover&quot; data-placement=&quot;left&quot; data-content=&quot;Vivamus sagittis lacus vel augue laoreet rutrum faucibus.&quot;&gt;
  Popover on left
&lt;/button&gt;&lt;/p&gt;

&lt;div class=&quot;spinner-border text-primary&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-secondary&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-success&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-danger&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-warning&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-info&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-light&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;
&lt;div class=&quot;spinner-border text-dark&quot; role=&quot;status&quot;&gt;
  &lt;span class=&quot;sr-only&quot;&gt;Loading...&lt;/span&gt;
&lt;/div&gt;

&lt;div aria-live=&quot;polite&quot; aria-atomic=&quot;true&quot; style=&quot;position: relative; min-height: 200px;&quot;&gt;
  &lt;!-- Position it --&gt;
  &lt;div style=&quot;position: absolute; top: 0; right: 0;&quot;&gt;

    &lt;!-- Then put toasts within --&gt;
    &lt;div class=&quot;toast&quot; role=&quot;alert&quot; aria-live=&quot;assertive&quot; aria-atomic=&quot;true&quot;&gt;
      &lt;div class=&quot;toast-header&quot;&gt;
        &lt;img src=&quot;http://placehold.it/150x150&quot; class=&quot;rounded mr-2&quot; alt=&quot;...&quot; /&gt;
        &lt;strong class=&quot;mr-auto&quot;&gt;Bootstrap&lt;/strong&gt;
        &lt;small class=&quot;text-muted&quot;&gt;just now&lt;/small&gt;
        &lt;button type=&quot;button&quot; class=&quot;ml-2 mb-1 close&quot; data-dismiss=&quot;toast&quot; aria-label=&quot;Close&quot;&gt;
          &lt;span aria-hidden=&quot;true&quot;&gt;&amp;times;&lt;/span&gt;
        &lt;/button&gt;
      &lt;/div&gt;
      &lt;div class=&quot;toast-body&quot;&gt;
        See? Just like this.
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=&quot;toast&quot; role=&quot;alert&quot; aria-live=&quot;assertive&quot; aria-atomic=&quot;true&quot;&gt;
      &lt;div class=&quot;toast-header&quot;&gt;
        &lt;img src=&quot;http://placehold.it/150x150&quot; class=&quot;rounded mr-2&quot; alt=&quot;...&quot; /&gt;
        &lt;strong class=&quot;mr-auto&quot;&gt;Bootstrap&lt;/strong&gt;
        &lt;small class=&quot;text-muted&quot;&gt;2 seconds ago&lt;/small&gt;
        &lt;button type=&quot;button&quot; class=&quot;ml-2 mb-1 close&quot; data-dismiss=&quot;toast&quot; aria-label=&quot;Close&quot;&gt;
          &lt;span aria-hidden=&quot;true&quot;&gt;&amp;times;&lt;/span&gt;
        &lt;/button&gt;
      &lt;/div&gt;
      &lt;div class=&quot;toast-body&quot;&gt;
        Heads up, toasts will stack automatically
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-toggle=&quot;tooltip&quot; data-placement=&quot;top&quot; title=&quot;Tooltip on top&quot;&gt;
  Tooltip on top
&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-toggle=&quot;tooltip&quot; data-placement=&quot;right&quot; title=&quot;Tooltip on right&quot;&gt;
  Tooltip on right
&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-toggle=&quot;tooltip&quot; data-placement=&quot;bottom&quot; title=&quot;Tooltip on bottom&quot;&gt;
  Tooltip on bottom
&lt;/button&gt;
&lt;button type=&quot;button&quot; class=&quot;btn btn-secondary&quot; data-toggle=&quot;tooltip&quot; data-placement=&quot;left&quot; title=&quot;Tooltip on left&quot;&gt;
  Tooltip on left
&lt;/button&gt;&lt;/p&gt;

&lt;div class=&quot;embed-responsive embed-responsive-16by9&quot;&gt;
  &lt;iframe class=&quot;embed-responsive-item&quot; src=&quot;https://www.youtube.com/embed/5qap5aO4i9A?rel=0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p class=&quot;user-select-all&quot;&gt;This paragraph will be entirely selected when clicked by the user.&lt;/p&gt;
&lt;p class=&quot;user-select-auto&quot;&gt;This paragraph has the default select behavior.&lt;/p&gt;
&lt;p class=&quot;user-select-none&quot;&gt;This paragraph will not be selectable when clicked by the user.&lt;/p&gt;

&lt;div class=&quot;overflow-auto&quot;&gt;...&lt;/div&gt;
&lt;div class=&quot;overflow-hidden&quot;&gt;...&lt;/div&gt;

&lt;div id=&quot;ytplayer&quot;&gt;&lt;/div&gt;

&lt;script&gt;
  // Load the IFrame Player API code asynchronously.
  var tag = document.createElement('script');
  tag.src = &quot;https://www.youtube.com/player_api&quot;;
  var firstScriptTag = document.getElementsByTagName('script')[0];
  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);

  // Replace the 'ytplayer' element with an &lt;iframe&gt; and
  // YouTube player after the API code downloads.
  var player;
  function onYouTubePlayerAPIReady() {
    player = new YT.Player('ytplayer', {
      height: '360',
      width: '640',
      videoId: 'M7lc1UVf-VE'
    });
  }
&lt;/script&gt;

&lt;p&gt;Links using markdown are normal and styled like this …&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://codepen.io/melnik909/pen/KGxdjY&quot;&gt;A link&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;But if you use the right class, it can look like this…&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://codepen.io/melnik909/pen/KGxdjY&quot; class=&quot;highlighted&quot;&gt;read more&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;making-charts-with-chartjs&quot;&gt;Making Charts with Chart.js&lt;/h4&gt;

&lt;canvas id=&quot;myChart&quot;&gt;&lt;/canvas&gt;

&lt;canvas id=&quot;myBarChart&quot; height=&quot;50&quot;&gt;&lt;/canvas&gt;

&lt;script&gt;
var ctx = document.getElementById('myBarChart').getContext('2d');
var myBarChart = new Chart(ctx, {
    type: 'horizontalBar',
    data: {
        labels: ['Red', 'Blue', 'Yellow', 'Green', 'Purple', 'Orange'],
        datasets: [{
            label: 'My Skills',
            data: [12, 19, 3, 5, 2, 3],
            borderWidth: 1
        }]
    },
    options: {
        scales: {
            yAxes: [{
                ticks: {
                    beginAtZero: true
                }
            }]
        }
    }
});
&lt;/script&gt;

&lt;script&gt;
var ctx = document.getElementById('myChart').getContext('2d');
var chart = new Chart(ctx, {
    // The type of chart we want to create
    type: 'line',

    // The data for our dataset
    data: {
        labels: ['A', 'B', 'C'],
        datasets: [
        {
            data: [10, 20, 30],
            backgroundColor: '#af90ca',
            label: 'Before'
        },
        {
            data: [50, 30, 40],
            backgroundColor: '#c46998',
            label: 'After'
        }
        ]
    },

    // Configuration options go here
    options: {}
});
&lt;/script&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;This is the first footnote. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:bignote&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Here’s one with multiple paragraphs and code.&lt;/p&gt;

      &lt;p&gt;Indent paragraphs to include them in the footnote.&lt;/p&gt;

      &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;{ my code }&lt;/code&gt;&lt;/p&gt;

      &lt;p&gt;Add as many paragraphs as you like. &lt;a href=&quot;#fnref:bignote&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Tyler Butler</name></author><category term="post" /><category term="styleguide" /><summary type="html">Markdown Bootstrap [Custom CSS]</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://placehold.it/750X300?text=Header+Image" /><media:content medium="image" url="http://placehold.it/750X300?text=Header+Image" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>